{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from supabase import create_client, Client\n",
    "from datetime import datetime, time\n",
    "from datetime import datetime, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para unificar todos los archivos en uno solo y poder trabajar sobre ese\n",
    "files = glob.glob(\"./BD/*.csv\")  \n",
    "data=pd.concat((pd.read_csv(i) for i in files), ignore_index=True)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('base de datos 2014-2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llevar las fechas a un mismo formato\n",
    "df=dd.read_csv('base de datos 2014-2018.csv')\n",
    "dates=[]\n",
    "for i in df['FlightDate']:\n",
    "    dates.append(datetime.strptime(i, \"%Y-%m-%d\"))\n",
    "df['FlightDate']=dates\n",
    "print(df['FlightDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=dd.read_csv('base de datos 2014-2018.csv',dtype={\n",
    "                     'CancellationCode': 'object',\n",
    "                     'Div1Airport': 'object',\n",
    "                     'Div1TailNum': 'object',\n",
    "                     'Div2Airport': 'object',\n",
    "                     'Div2TailNum': 'object',\n",
    "                     'Div3Airport': 'object'\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar columnas innecesarias\n",
    "base_datos=b.drop(columns=['DistanceGroup','ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups', 'ArrTimeBlk','DepDelayMinutes', 'DepDel15', \n",
    "                           'DepartureDelayGroups', 'DepTimeBlk','CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay',\n",
    "                           'IATA_CODE_Reporting_Airline', \"DivReachedDest\",\"DivActualElapsedTime\",\"DivArrDelay\",\"DivDistance\",\"Div1Airport\",\n",
    "                           \"Div1AirportID\",\"Div1AirportSeqID\",\"Div1WheelsOn\",\"Div1TotalGTime\",\"Div1LongestGTime\",\"Div1WheelsOff\",\"Div1TailNum\",\n",
    "\n",
    "                           \"Div2Airport\",\"Div2AirportID\",\"Div2AirportSeqID\",\"Div2WheelsOn\",\"Div2TotalGTime\",\"Div2LongestGTime\",\"Div2WheelsOff\", \n",
    "                           \"Div2TailNum\",\"Div3Airport\",\"Div3AirportID\",\"Div3AirportSeqID\",\"Div3WheelsOn\",\"Div3TotalGTime\",\"Div3LongestGTime\",\n",
    "                           \"Div3WheelsOff\",\"Div3TailNum\",\"Div4Airport\",\"Div4AirportID\",\"Div4AirportSeqID\",\"Div4WheelsOn\",\"Div4TotalGTime\",\n",
    "                           \"Div4LongestGTime\",\"Div4WheelsOff\",\"Div4TailNum\",\"Div5Airport\",\"Div5AirportID\",\"Div5AirportSeqID\",\"Div5WheelsOn\",\n",
    "                           \"Div5TotalGTime\",\"Div5LongestGTime\",\"Div5WheelsOff\",\"Div5TailNum\", 'Tail_Number', 'Year',\t'Quarter',\t'Month', 'DayofMonth',\t\n",
    "                           'DayOfWeek', 'DivAirportLandings', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'TaxiOut', 'TaxiIn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c098d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_datos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificar todos los nombres de las variables\n",
    "data=dd.read_csv('base de datos 2014-2018(1).csv')\n",
    "names=['FL_DATE', 'OP_UNIQUE_CARRIER', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER', \n",
    "       'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID', 'ORIGIN_AIRPORT_SEQ_ID', \n",
    "       'ORIGIN_CITY_MARKET_ID', 'ORIGIN', 'ORIGIN_CITY_NAME', 'ORIGIN_STATE_ABR', \n",
    "       'ORIGIN_STATE_FIPS', 'ORIGIN_STATE_NM', 'ORIGIN_WAC', 'DEST_AIRPORT_ID', \n",
    "       'DEST_AIRPORT_SEQ_ID', 'DEST_CITY_MARKET_ID', 'DEST', 'DEST_CITY_NAME', \n",
    "       'DEST_STATE_ABR', 'DEST_STATE_FIPS', 'DEST_STATE_NM', 'DEST_WAC', \n",
    "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'WHEELS_OFF', 'WHEELS_ON', \n",
    "       'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CANCELLED', 'DIVERTED', \n",
    "       'AIR_TIME', 'FLIGHTS', 'DISTANCE']\n",
    "data.columns=names\n",
    "data.to_csv('base de datos 2014-2018(2).csv', index= False, single_file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa588921",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"base de datos 2014-2018(2).csv\" \n",
    "df = dd.read_csv(csv_file_path) \n",
    "df.co\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"fligth_database\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Katy+58029986\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 3. Eliminar tablas existentes (si es necesario)\n",
    "# cur.execute(\"DROP TABLE IF EXISTS aircrafts;\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS airports;\")\n",
    "#cur.execute(\"DROP TABLE IF EXISTS flights;\")\n",
    "#cur.execute(\"DROP TABLE IF EXISTS airlines;\")\n",
    "\n",
    "# 4. Crear las tablas necesarias\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS airlines (\n",
    "    airline_id INT PRIMARY KEY,\n",
    "    unique_carrier VARCHAR(10)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS airports (\n",
    "    airport_id INT,\n",
    "    airport_seq_id INT,\n",
    "    city_market_id VARCHAR(50),\n",
    "    code VARCHAR(50),\n",
    "    city_name VARCHAR(50),\n",
    "    state_abr VARCHAR(50),\n",
    "    state_fips VARCHAR(50),\n",
    "    state_name VARCHAR(50),\n",
    "    wac INT,\n",
    "    PRIMARY KEY (airport_id, airport_seq_id)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS flights (\n",
    "    flight_id SERIAL PRIMARY KEY,\n",
    "    fl_date DATE,\n",
    "    op_unique_carrier VARCHAR(10),\n",
    "    op_carrier_airline_id INT,\n",
    "    op_carrier VARCHAR(10),\n",
    "    op_carrier_fl_num VARCHAR(10),\n",
    "    origin_airport_id INT,\n",
    "    dest_airport_id INT,\n",
    "    crs_dep_time TIME,\n",
    "    dep_time TIME,\n",
    "    dep_delay FLOAT,\n",
    "    wheels_off TIME,\n",
    "    wheels_on TIME,\n",
    "    crs_arr_time TIME,\n",
    "    arr_time TIME,\n",
    "    arr_delay FLOAT,\n",
    "    cancelled BOOLEAN,\n",
    "    diverted BOOLEAN,\n",
    "    air_time FLOAT,\n",
    "    distance FLOAT,\n",
    "    flights FLOAT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "def convert_hhmm(time_val):\n",
    "    \"\"\"Convierte valores HHMM a objetos TIME.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(time_val) or time_val == '':\n",
    "            return None\n",
    "    \n",
    "        time_num = int(float(time_val))\n",
    "        \n",
    "        if time_num == 2400:\n",
    "            return time(23, 59, 59)\n",
    "            \n",
    "        if time_num < 0 or time_num > 2359:\n",
    "            return None\n",
    "        \n",
    "        time_str = f\"{time_num:04d}\"\n",
    "    \n",
    "        hours = int(time_str[:2])\n",
    "        minutes = int(time_str[2:])\n",
    "        \n",
    "        if hours > 23 or minutes > 59:\n",
    "            return None\n",
    "            \n",
    "        return time(hours, minutes, 0)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def parse_fl_date(date_val):\n",
    "    \"\"\"Versión robusta para manejar múltiples formatos de fecha.\"\"\"\n",
    "    if pd.isna(date_val):\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        parsed = pd.to_datetime(date_val, errors='coerce')\n",
    "        if not pd.isna(parsed):\n",
    "            return parsed.date()\n",
    "            \n",
    "\n",
    "        date_str = str(date_val).strip()\n",
    "       \n",
    "        if date_str.isdigit() and len(date_str) == 8:\n",
    "            return datetime.strptime(date_str, \"%Y%m%d\").date()\n",
    "            \n",
    "        for fmt in (\"%m/%d/%Y\", \"%Y-%m-%d\", \"%d-%m-%Y\", \"%m-%d-%Y\"):\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt).date()\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date {date_val}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "airlines = df[['op_carrier_airline_id', 'op_unique_carrier']].drop_duplicates()\n",
    "cur.executemany(\"\"\"\n",
    "    INSERT INTO airlines (airline_id, unique_carrier)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (airline_id) DO NOTHING;\n",
    "\"\"\", [(row['op_carrier_airline_id'], row['op_unique_carrier']) for _, row in airlines.iterrows()])\n",
    "\n",
    "origin_airports = df[['origin_airport_id', 'origin_airport_seq_id', 'origin_city_market_id',\n",
    "                      'origin', 'origin_city_name', 'origin_state_abr', 'origin_state_fips',\n",
    "                      'origin_state_nm', 'origin_wac']].drop_duplicates()\n",
    "\n",
    "dest_airports = df[['dest_airport_id', 'dest_airport_seq_id', 'dest_city_market_id',\n",
    "                    'dest', 'dest_city_name', 'dest_state_abr', 'dest_state_fips',\n",
    "                    'dest_state_nm', 'dest_wac']].drop_duplicates()\n",
    "\n",
    "origin_airports.columns = ['airport_id', 'airport_seq_id', 'city_market_id',\n",
    "                           'code', 'city_name', 'state_abr', 'state_fips',\n",
    "                           'state_name', 'wac']\n",
    "\n",
    "dest_airports.columns = origin_airports.columns\n",
    "\n",
    "airports = dd.concat([origin_airports, dest_airports]).drop_duplicates()\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "    INSERT INTO airports (airport_id, airport_seq_id, city_market_id,\n",
    "                          code, city_name, state_abr, state_fips,\n",
    "                          state_name, wac)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (airport_id, airport_seq_id) DO NOTHING;\n",
    "\"\"\", [tuple(row) for _, row in airports.iterrows()])\n",
    "\n",
    "#Insertar los vuelos en `flights`\n",
    "for _, row in df.iterrows():\n",
    "    # Convertir todos los campos\n",
    "    fl_date = parse_fl_date(row['fl_date'])\n",
    "    \n",
    "    crs_dep_time = convert_hhmm(row['crs_dep_time'])\n",
    "    dep_time = convert_hhmm(row['dep_time'])\n",
    "    wheels_off = convert_hhmm(row['wheels_off'])\n",
    "    wheels_on = convert_hhmm(row['wheels_on'])\n",
    "    crs_arr_time = convert_hhmm(row['crs_arr_time'])\n",
    "    arr_time = convert_hhmm(row['arr_time'])   \n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO flights (fl_date, op_unique_carrier, op_carrier_airline_id,\n",
    "                             op_carrier, op_carrier_fl_num,\n",
    "                             origin_airport_id, dest_airport_id,\n",
    "                             crs_dep_time, dep_time, dep_delay, wheels_off,\n",
    "                             wheels_on, crs_arr_time, arr_time, arr_delay,\n",
    "                             cancelled, diverted, air_time,\n",
    "                             distance, flights)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s);\n",
    "    \"\"\", (\n",
    "        fl_date,\n",
    "        row['op_unique_carrier'],\n",
    "        row['op_carrier_airline_id'],\n",
    "        row['op_carrier'],\n",
    "        row['op_carrier_fl_num'],\n",
    "        row['origin_airport_id'],\n",
    "        row['dest_airport_id'],\n",
    "        crs_dep_time,\n",
    "        dep_time,\n",
    "        row['dep_delay'],\n",
    "        wheels_off,\n",
    "        wheels_on,\n",
    "        crs_arr_time,\n",
    "        arr_time,\n",
    "        row['arr_delay'],\n",
    "        bool(row['cancelled']),\n",
    "        bool(row['diverted']),\n",
    "        row['air_time'],\n",
    "        row['distance'],\n",
    "        row['flights']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
